{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "sys.path.append(os.path.abspath(\"../../mathematical_models\"))\n",
    "from mathematical_models.s_on_f import ScalarOnFunctionModel\n",
    "from mathematical_models.f_on_f import FunctionOnFunctionModel\n",
    "from mathematical_models.s_on_s import ScalarOnScalarModel\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../optimizers\"))\n",
    "from optimizers.nbdo import NBDO\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../utilities\"))\n",
    "from utilities.plotting.plot_fun import subplot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:54:54.890940: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thodorisladas/miniforge3/envs/optidex/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "4/4 [==============================] - 5s 460ms/step - loss: 38392140.0000 - val_loss: 230239.9219\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 2s 348ms/step - loss: 77017.1875 - val_loss: 587.1858\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 540.6711 - val_loss: 456.9918\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 433.0406 - val_loss: 384.6909\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 367.4070 - val_loss: 332.0948\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 314.2935 - val_loss: 242.6597\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 219.1419 - val_loss: 176.0122\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 163.0921 - val_loss: 134.2742\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 125.3737 - val_loss: 107.3961\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 101.5530 - val_loss: 89.4886\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 85.2163 - val_loss: 76.3715\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 73.0154 - val_loss: 65.4533\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 62.1578 - val_loss: 55.0373\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 52.4086 - val_loss: 46.8874\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 44.8235 - val_loss: 40.4805\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 38.8256 - val_loss: 35.3485\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 33.9900 - val_loss: 31.1299\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 29.9598 - val_loss: 27.2579\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 26.1575 - val_loss: 23.7943\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 22.8944 - val_loss: 20.9729\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 20.2377 - val_loss: 18.6707\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 18.0327 - val_loss: 16.5899\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 16.0172 - val_loss: 14.7518\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 14.2393 - val_loss: 13.1002\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 12.6726 - val_loss: 11.7385\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 11.3870 - val_loss: 10.6182\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 10.3244 - val_loss: 9.6813\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 9.4355 - val_loss: 8.8955\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 8.6889 - val_loss: 8.2372\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 8.0625 - val_loss: 7.6800\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 7.5317 - val_loss: 7.2053\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 7.0737 - val_loss: 6.7707\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 6.6481 - val_loss: 6.3703\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 6.2660 - val_loss: 6.0340\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 5.9479 - val_loss: 5.7577\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 5.6867 - val_loss: 5.5259\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 5.4660 - val_loss: 5.3337\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 5.2853 - val_loss: 5.1786\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 5.1392 - val_loss: 5.0520\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 5.0193 - val_loss: 4.9454\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.9177 - val_loss: 4.8551\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.8322 - val_loss: 4.7797\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.7606 - val_loss: 4.7161\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 4.6989 - val_loss: 4.6589\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 4.6443 - val_loss: 4.6096\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 4.5966 - val_loss: 4.5651\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.5538 - val_loss: 4.5257\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.5155 - val_loss: 4.4921\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 4.4847 - val_loss: 4.4677\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 4.4605 - val_loss: 4.4453\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 4.4410 - val_loss: 4.4302\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.4264 - val_loss: 4.4155\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.4102 - val_loss: 4.3996\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.3977 - val_loss: 4.3911\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.3864 - val_loss: 4.3742\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 350ms/step - loss: 4.3706 - val_loss: 4.3607\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 4.3565 - val_loss: 4.3455\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.3423 - val_loss: 4.3353\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 4.3324 - val_loss: 4.3245\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.3202 - val_loss: 4.3082\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.3048 - val_loss: 4.3006\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 4.2997 - val_loss: 4.2946\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 4.2908 - val_loss: 4.2798\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 4.2772 - val_loss: 4.2707\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.2693 - val_loss: 4.2671\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.2690 - val_loss: 4.2704\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 4.2630 - val_loss: 4.2513\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 4.2493 - val_loss: 4.2498\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 4.2456 - val_loss: 4.2368\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.2324 - val_loss: 4.2285\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.2275 - val_loss: 4.2349\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 4.2334 - val_loss: 4.2273\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 4.2190 - val_loss: 4.2162\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 4.2141 - val_loss: 4.2221\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 4.2202 - val_loss: 4.2323\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 4.2289 - val_loss: 4.2486\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 4.2397 - val_loss: 4.2161\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 4.2023 - val_loss: 4.2049\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 4.2149 - val_loss: 4.2775\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 4.2531 - val_loss: 4.2156\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 4.2038 - val_loss: 4.2196\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 4.2259 - val_loss: 4.2603\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.2393 - val_loss: 4.2270\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0941\n",
      "Function value obtained: 5.6378\n",
      "Current minimum: 5.6378\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0505\n",
      "Function value obtained: 6.6696\n",
      "Current minimum: 5.6378\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0524\n",
      "Function value obtained: 6.0857\n",
      "Current minimum: 5.6378\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0611\n",
      "Function value obtained: 4.5921\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.3163\n",
      "Function value obtained: 5.2426\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1610\n",
      "Function value obtained: 6.1884\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1065\n",
      "Function value obtained: 5.1854\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1026\n",
      "Function value obtained: 4.6006\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1824\n",
      "Function value obtained: 7.9455\n",
      "Current minimum: 4.5921\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1667\n",
      "Function value obtained: 7.9351\n",
      "Current minimum: 4.5921\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Time taken: 121.06 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "N = 136 # runs\n",
    "Kx = [[15]]\n",
    "epochs = 100\n",
    "order = 2\n",
    "s_on_s_model = ScalarOnScalarModel(Kx=Kx[0], order=order)\n",
    "optimizer_s_on_s = NBDO(model=s_on_s_model, latent_dim=4)\n",
    "optimizer_s_on_s.compute_train_set(num_designs=1_000, runs=N, type=\"random\")\n",
    "history = optimizer_s_on_s.fit(epochs=epochs, patience=5, batch_size=2**8)\n",
    "best_cr, best_des = optimizer_s_on_s.optimize()\n",
    "end_time = time()\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming best_des is already defined and has shape (136, 15)\n",
    "columns = [f'x{i}' for i in range(1, 16)]\n",
    "best_des_df = pd.DataFrame(best_des, columns=columns)\n",
    "best_des_df.to_csv('./design7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.ylim(0, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LOOP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for Kx = [15], N = 136...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 22:31:01.029499: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thodorisladas/miniforge3/envs/optidex/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "4/4 [==============================] - 5s 487ms/step - loss: 40820848.0000 - val_loss: 2234.3369\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1507.4650 - val_loss: 942.7389\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 856.7014 - val_loss: 715.4802\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 663.0234 - val_loss: 576.0481\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 538.7430 - val_loss: 476.8484\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 447.5392 - val_loss: 392.1435\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 360.8670 - val_loss: 295.0799\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 270.0762 - val_loss: 224.1542\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 206.9509 - val_loss: 171.0955\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 155.8084 - val_loss: 124.2524\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 112.8402 - val_loss: 91.3537\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 84.0632 - val_loss: 69.2992\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 63.7444 - val_loss: 52.4968\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 48.3323 - val_loss: 40.2092\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 37.4337 - val_loss: 32.1288\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 30.2185 - val_loss: 26.5628\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 25.1646 - val_loss: 22.4873\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 21.4152 - val_loss: 19.2766\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 18.3575 - val_loss: 16.5540\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 15.8288 - val_loss: 14.4316\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 13.8577 - val_loss: 12.7339\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 12.2407 - val_loss: 11.2703\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 10.8718 - val_loss: 10.1035\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 9.7837 - val_loss: 9.1705\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 8.9113 - val_loss: 8.4162\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 8.2029 - val_loss: 7.7934\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 7.6166 - val_loss: 7.2775\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 7.1291 - val_loss: 6.8449\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 6.7203 - val_loss: 6.4824\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 6.3774 - val_loss: 6.1757\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 6.0861 - val_loss: 5.9063\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 5.8266 - val_loss: 5.6662\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 5.5952 - val_loss: 5.4476\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 5.3873 - val_loss: 5.2643\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 5.2153 - val_loss: 5.1158\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 5.0743 - val_loss: 4.9868\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 4.9527 - val_loss: 4.8797\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.8506 - val_loss: 4.7868\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.7621 - val_loss: 4.7096\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 4.6898 - val_loss: 4.6478\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 4.6329 - val_loss: 4.5996\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.5878 - val_loss: 4.5659\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.5585 - val_loss: 4.5368\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.5286 - val_loss: 4.5047\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.4958 - val_loss: 4.4764\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 364ms/step - loss: 4.4703 - val_loss: 4.4541\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 4.4492 - val_loss: 4.4337\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 4.4260 - val_loss: 4.4071\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 4.4032 - val_loss: 4.3977\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 4.3922 - val_loss: 4.3754\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 4.3725 - val_loss: 4.3647\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 4.3620 - val_loss: 4.3535\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 4.3517 - val_loss: 4.3444\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 4.3387 - val_loss: 4.3250\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 4.3217 - val_loss: 4.3144\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.3123 - val_loss: 4.3101\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 4.3105 - val_loss: 4.3071\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 4.3039 - val_loss: 4.3006\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 4.3003 - val_loss: 4.2946\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 4.2908 - val_loss: 4.2800\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 4.2799 - val_loss: 4.2805\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 4.2827 - val_loss: 4.2833\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.2809 - val_loss: 4.2699\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.2663 - val_loss: 4.2608\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.2636 - val_loss: 4.2761\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.2732 - val_loss: 4.2576\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4.2529 - val_loss: 4.2516\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 4.2553 - val_loss: 4.2702\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 4.2702 - val_loss: 4.2857\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 4.2785 - val_loss: 4.2638\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 4.2550 - val_loss: 4.2581\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 4.2574 - val_loss: 4.2649\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0897\n",
      "Function value obtained: 4.3316\n",
      "Current minimum: 4.3316\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0583\n",
      "Function value obtained: 5.1715\n",
      "Current minimum: 4.3316\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0705\n",
      "Function value obtained: 51.6144\n",
      "Current minimum: 4.3316\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0348\n",
      "Function value obtained: 4.2858\n",
      "Current minimum: 4.2858\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1874\n",
      "Function value obtained: 4.5161\n",
      "Current minimum: 4.2858\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1571\n",
      "Function value obtained: 5.0275\n",
      "Current minimum: 4.2858\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1547\n",
      "Function value obtained: 4.3652\n",
      "Current minimum: 4.2858\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1532\n",
      "Function value obtained: 4.2635\n",
      "Current minimum: 4.2635\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1351\n",
      "Function value obtained: 4.8111\n",
      "Current minimum: 4.2635\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1374\n",
      "Function value obtained: 4.6497\n",
      "Current minimum: 4.2635\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Finished: Kx=[15], N=136\n",
      "Time taken: 106.30 seconds\n",
      "Best criterion: 4.263490598502859\n",
      "\n",
      "\n",
      "Running for Kx = [15], N = 142...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 5s 438ms/step - loss: 40579672.0000 - val_loss: 7397.7861\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 6475.4673 - val_loss: 4896.7583\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 4488.2744 - val_loss: 3685.2512\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 3424.9373 - val_loss: 2875.2051\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 2657.0437 - val_loss: 2075.4438\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 1840.5312 - val_loss: 1350.8560\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 1214.9402 - val_loss: 943.9688\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 856.7635 - val_loss: 678.7953\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 622.0670 - val_loss: 504.3489\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 462.7647 - val_loss: 379.0268\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 350.2592 - val_loss: 292.5812\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 272.1822 - val_loss: 230.1380\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 213.8416 - val_loss: 180.6831\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 168.5149 - val_loss: 144.0915\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 134.4259 - val_loss: 114.6667\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 107.2253 - val_loss: 91.8212\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 85.6077 - val_loss: 72.3368\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 67.2384 - val_loss: 56.8851\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 53.1759 - val_loss: 45.7779\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 43.0285 - val_loss: 37.3805\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 35.1888 - val_loss: 30.7933\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 29.1234 - val_loss: 25.8166\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 24.5114 - val_loss: 21.8385\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 20.7575 - val_loss: 18.5770\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 17.6894 - val_loss: 15.8871\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 15.1721 - val_loss: 13.7048\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 13.1152 - val_loss: 11.9314\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 11.4616 - val_loss: 10.5065\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 10.0947 - val_loss: 9.2209\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 8.8674 - val_loss: 8.1346\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 7.8438 - val_loss: 7.2258\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 6.9915 - val_loss: 6.5130\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 6.3307 - val_loss: 5.9516\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 5.8037 - val_loss: 5.4977\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 5.3790 - val_loss: 5.1372\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 5.0468 - val_loss: 4.8642\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 4.7942 - val_loss: 4.6492\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 4.5923 - val_loss: 4.4762\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 4.4312 - val_loss: 4.3398\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 358ms/step - loss: 4.3041 - val_loss: 4.2310\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 4.2024 - val_loss: 4.1441\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 4.1205 - val_loss: 4.0720\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 4.0533 - val_loss: 4.0146\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 4.0000 - val_loss: 3.9710\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 3.9595 - val_loss: 3.9372\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 3.9284 - val_loss: 3.9116\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 3.9054 - val_loss: 3.8920\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 3.8869 - val_loss: 3.8761\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 3.8721 - val_loss: 3.8636\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 3.8605 - val_loss: 3.8534\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 3.8498 - val_loss: 3.8429\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 3.8401 - val_loss: 3.8335\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 3.8305 - val_loss: 3.8255\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 3.8235 - val_loss: 3.8211\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 3.8185 - val_loss: 3.8132\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 3.8100 - val_loss: 3.8052\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 3.8035 - val_loss: 3.8012\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 3.8004 - val_loss: 3.7985\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 3.7968 - val_loss: 3.7945\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 3.7937 - val_loss: 3.7920\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 3.7905 - val_loss: 3.7892\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 3.7866 - val_loss: 3.7814\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 3.7809 - val_loss: 3.7843\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 3.7820 - val_loss: 3.7784\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 3.7777 - val_loss: 3.7801\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 3.7781 - val_loss: 3.7783\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 3.7748 - val_loss: 3.7780\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 3.7775 - val_loss: 3.7837\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 3.7760 - val_loss: 3.7775\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 3.7823 - val_loss: 3.7911\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 2s 364ms/step - loss: 3.7803 - val_loss: 3.7767\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 3.7721 - val_loss: 3.7971\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 3.7893 - val_loss: 3.7891\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 3.8192 - val_loss: 3.9153\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 3.7996 - val_loss: 3.7317\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 3.7315 - val_loss: 3.7492\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 3.7643 - val_loss: 3.8528\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 3.8230 - val_loss: 3.7727\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 3.7578 - val_loss: 3.7681\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 3.7649 - val_loss: 3.7871\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0639\n",
      "Function value obtained: 3.7845\n",
      "Current minimum: 3.7845\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0524\n",
      "Function value obtained: 3.7628\n",
      "Current minimum: 3.7628\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0772\n",
      "Function value obtained: 4.5883\n",
      "Current minimum: 3.7628\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0757\n",
      "Function value obtained: 3.7308\n",
      "Current minimum: 3.7308\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1705\n",
      "Function value obtained: 3.8519\n",
      "Current minimum: 3.7308\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1889\n",
      "Function value obtained: 3.7940\n",
      "Current minimum: 3.7308\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1308\n",
      "Function value obtained: 3.7301\n",
      "Current minimum: 3.7301\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1485\n",
      "Function value obtained: 3.8857\n",
      "Current minimum: 3.7301\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1832\n",
      "Function value obtained: 3.9128\n",
      "Current minimum: 3.7301\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1705\n",
      "Function value obtained: 3.7988\n",
      "Current minimum: 3.7301\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Finished: Kx=[15], N=142\n",
      "Time taken: 116.99 seconds\n",
      "Best criterion: 3.730115366136568\n",
      "\n",
      "\n",
      "Running for Kx = [15], N = 160...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 5s 486ms/step - loss: 39326120.0000 - val_loss: 1889.2596\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 348ms/step - loss: 1381.9189 - val_loss: 681.5995\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 548.7750 - val_loss: 354.9195\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 297.2690 - val_loss: 201.5062\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 168.8888 - val_loss: 117.4800\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 99.8352 - val_loss: 72.6379\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 62.3345 - val_loss: 45.6200\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 39.6792 - val_loss: 30.5683\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 337ms/step - loss: 27.1256 - val_loss: 22.0597\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 337ms/step - loss: 19.9910 - val_loss: 16.9671\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 15.5314 - val_loss: 13.4804\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 12.4801 - val_loss: 11.0961\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 10.3530 - val_loss: 9.3016\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 8.7337 - val_loss: 7.9584\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 7.5316 - val_loss: 6.9593\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 2s 369ms/step - loss: 6.6221 - val_loss: 6.1668\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 5.8956 - val_loss: 5.5353\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 5.3213 - val_loss: 5.0426\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 4.8670 - val_loss: 4.6300\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 4.4831 - val_loss: 4.2846\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 4.1659 - val_loss: 4.0080\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 3.9132 - val_loss: 3.7894\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 3.7140 - val_loss: 3.6184\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 3.5571 - val_loss: 3.4801\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 3.4298 - val_loss: 3.3661\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 3.3241 - val_loss: 3.2702\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 3.2353 - val_loss: 3.1886\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 3.1602 - val_loss: 3.1221\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 3.0999 - val_loss: 3.0710\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 3.0537 - val_loss: 3.0314\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 3.0176 - val_loss: 2.9986\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.9873 - val_loss: 2.9721\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 2.9626 - val_loss: 2.9492\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.9416 - val_loss: 2.9305\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.9242 - val_loss: 2.9143\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.9088 - val_loss: 2.9008\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8956 - val_loss: 2.8882\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 2.8846 - val_loss: 2.8801\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 2.8772 - val_loss: 2.8726\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8702 - val_loss: 2.8674\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8654 - val_loss: 2.8620\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 2.8605 - val_loss: 2.8588\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8578 - val_loss: 2.8556\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 337ms/step - loss: 2.8549 - val_loss: 2.8539\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.8533 - val_loss: 2.8515\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8508 - val_loss: 2.8497\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8492 - val_loss: 2.8482\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8478 - val_loss: 2.8493\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 2s 392ms/step - loss: 2.8484 - val_loss: 2.8441\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8416 - val_loss: 2.8408\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 2.8402 - val_loss: 2.8410\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 1s 345ms/step - loss: 2.8377 - val_loss: 2.8336\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.8315 - val_loss: 2.8297\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 2.8292 - val_loss: 2.8303\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.8280 - val_loss: 2.8249\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8237 - val_loss: 2.8248\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8233 - val_loss: 2.8262\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8236 - val_loss: 2.8191\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 2.8170 - val_loss: 2.8194\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 1s 338ms/step - loss: 2.8193 - val_loss: 2.8208\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 2.8193 - val_loss: 2.8224\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8187 - val_loss: 2.8174\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8151 - val_loss: 2.8154\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8142 - val_loss: 2.8170\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8154 - val_loss: 2.8204\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.8173 - val_loss: 2.8201\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 2.8154 - val_loss: 2.8153\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 1s 345ms/step - loss: 2.8108 - val_loss: 2.8115\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8083 - val_loss: 2.8136\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8126 - val_loss: 2.8234\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 2.8160 - val_loss: 2.8147\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.8085 - val_loss: 2.8114\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8090 - val_loss: 2.8231\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 2.8202 - val_loss: 2.8279\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8189 - val_loss: 2.8033\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.7994 - val_loss: 2.8096\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 2.8096 - val_loss: 2.8284\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8137 - val_loss: 2.8129\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 2.8062 - val_loss: 2.8131\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 1s 342ms/step - loss: 2.8099 - val_loss: 2.8061\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0651\n",
      "Function value obtained: 2.9191\n",
      "Current minimum: 2.9191\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0544\n",
      "Function value obtained: 2.8477\n",
      "Current minimum: 2.8477\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0679\n",
      "Function value obtained: 3.0639\n",
      "Current minimum: 2.8477\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0786\n",
      "Function value obtained: 2.8091\n",
      "Current minimum: 2.8091\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.4192\n",
      "Function value obtained: 2.7938\n",
      "Current minimum: 2.7938\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1608\n",
      "Function value obtained: 2.8685\n",
      "Current minimum: 2.7938\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1769\n",
      "Function value obtained: 3.1374\n",
      "Current minimum: 2.7938\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4797\n",
      "Function value obtained: 3.0396\n",
      "Current minimum: 2.7938\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1365\n",
      "Function value obtained: 2.9282\n",
      "Current minimum: 2.7938\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1533\n",
      "Function value obtained: 3.0311\n",
      "Current minimum: 2.7938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Finished: Kx=[15], N=160\n",
      "Time taken: 125.47 seconds\n",
      "Best criterion: 2.7937665394548263\n",
      "\n",
      "\n",
      "Running for Kx = [20], N = 231...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 10s 1s/step - loss: 81151072.0000 - val_loss: 635.8419\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 317.1921 - val_loss: 96.1333\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 4s 894ms/step - loss: 83.1252 - val_loss: 58.7724\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 4s 906ms/step - loss: 53.6179 - val_loss: 42.5733\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 4s 899ms/step - loss: 39.6236 - val_loss: 33.2169\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 4s 892ms/step - loss: 31.5428 - val_loss: 27.6401\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 4s 890ms/step - loss: 26.4798 - val_loss: 23.5070\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 4s 900ms/step - loss: 22.4751 - val_loss: 19.9010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 18.9464 - val_loss: 16.3426\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 4s 904ms/step - loss: 15.4057 - val_loss: 13.1549\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 901ms/step - loss: 12.5058 - val_loss: 11.0184\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 4s 902ms/step - loss: 10.6043 - val_loss: 9.6092\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 4s 910ms/step - loss: 9.3143 - val_loss: 8.6209\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 4s 907ms/step - loss: 8.4160 - val_loss: 7.9189\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 4s 967ms/step - loss: 7.7567 - val_loss: 7.3374\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 7.1852 - val_loss: 6.7945\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 6.6695 - val_loss: 6.3730\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 4s 909ms/step - loss: 6.2867 - val_loss: 6.0815\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.0124 - val_loss: 5.8397\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 4s 907ms/step - loss: 5.7838 - val_loss: 5.6456\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 4s 894ms/step - loss: 5.6002 - val_loss: 5.4928\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 5.4586 - val_loss: 5.3660\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 5.3368 - val_loss: 5.2605\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 4s 902ms/step - loss: 5.2360 - val_loss: 5.1684\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 5.1486 - val_loss: 5.1013\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 4s 973ms/step - loss: 5.0913 - val_loss: 5.0554\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 5.0459 - val_loss: 5.0181\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 5.0127 - val_loss: 4.9886\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 4s 909ms/step - loss: 4.9850 - val_loss: 4.9679\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 4.9636 - val_loss: 4.9410\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 4s 922ms/step - loss: 4.9362 - val_loss: 4.9166\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 4.9123 - val_loss: 4.8857\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 4.8800 - val_loss: 4.8612\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.8576 - val_loss: 4.8365\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 4.8335 - val_loss: 4.8129\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 4s 914ms/step - loss: 4.8089 - val_loss: 4.7944\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 4s 963ms/step - loss: 4.7927 - val_loss: 4.7760\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 4.7717 - val_loss: 4.7530\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 4.7506 - val_loss: 4.7399\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 4.7399 - val_loss: 4.7255\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 4s 929ms/step - loss: 4.7206 - val_loss: 4.7017\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.6995 - val_loss: 4.6947\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 4.6952 - val_loss: 4.6832\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 4s 930ms/step - loss: 4.6799 - val_loss: 4.6672\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 4.6658 - val_loss: 4.6567\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 4.6548 - val_loss: 4.6403\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 4.6370 - val_loss: 4.6275\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 4.6279 - val_loss: 4.6249\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 4.6251 - val_loss: 4.6165\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 4.6148 - val_loss: 4.6044\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 4.6029 - val_loss: 4.5983\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.6003 - val_loss: 4.5994\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 4.5989 - val_loss: 4.5883\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 4.5862 - val_loss: 4.5771\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 4s 956ms/step - loss: 4.5764 - val_loss: 4.5733\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 4.5752 - val_loss: 4.5715\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 4.5704 - val_loss: 4.5590\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 4.5586 - val_loss: 4.5559\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.5580 - val_loss: 4.5521\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 4s 972ms/step - loss: 4.5485 - val_loss: 4.5367\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 4.5371 - val_loss: 4.5379\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.5397 - val_loss: 4.5335\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 4.5327 - val_loss: 4.5219\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 4.5207 - val_loss: 4.5160\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.5166 - val_loss: 4.5154\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 4.5167 - val_loss: 4.5095\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 4.5087 - val_loss: 4.5011\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 4s 987ms/step - loss: 4.4998 - val_loss: 4.4918\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 4.4914 - val_loss: 4.4896\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 4.4919 - val_loss: 4.4915\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 4s 964ms/step - loss: 4.4909 - val_loss: 4.4804\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 4.4797 - val_loss: 4.4763\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 4.4752 - val_loss: 4.4695\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 4.4709 - val_loss: 4.4719\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 4.4727 - val_loss: 4.4641\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.4632 - val_loss: 4.4594\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 4.4594 - val_loss: 4.4545\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 4s 913ms/step - loss: 4.4536 - val_loss: 4.4521\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.4541 - val_loss: 4.4546\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 4s 922ms/step - loss: 4.4544 - val_loss: 4.4481\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 4s 910ms/step - loss: 4.4478 - val_loss: 4.4425\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 4.4413 - val_loss: 4.4367\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 4.4367 - val_loss: 4.4387\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 4s 910ms/step - loss: 4.4390 - val_loss: 4.4382\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 4.4401 - val_loss: 4.4456\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 4s 998ms/step - loss: 4.4431 - val_loss: 4.4320\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 4s 922ms/step - loss: 4.4304 - val_loss: 4.4269\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 4s 919ms/step - loss: 4.4295 - val_loss: 4.4291\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 4.4295 - val_loss: 4.4280\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 4.4284 - val_loss: 4.4230\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.4249 - val_loss: 4.4280\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 4.4370 - val_loss: 4.4435\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 4.4452 - val_loss: 4.4299\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 4.4360 - val_loss: 4.4340\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.4430 - val_loss: 4.4630\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0951\n",
      "Function value obtained: 4.4587\n",
      "Current minimum: 4.4587\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0688\n",
      "Function value obtained: 4.8608\n",
      "Current minimum: 4.4587\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0839\n",
      "Function value obtained: 4.4919\n",
      "Current minimum: 4.4587\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0749\n",
      "Function value obtained: 4.4498\n",
      "Current minimum: 4.4498\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1972\n",
      "Function value obtained: 4.7495\n",
      "Current minimum: 4.4498\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1818\n",
      "Function value obtained: 4.7370\n",
      "Current minimum: 4.4498\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1788\n",
      "Function value obtained: 4.4622\n",
      "Current minimum: 4.4498\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1681\n",
      "Function value obtained: 4.4139\n",
      "Current minimum: 4.4139\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1514\n",
      "Function value obtained: 4.4118\n",
      "Current minimum: 4.4118\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1257\n",
      "Function value obtained: 4.4172\n",
      "Current minimum: 4.4118\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Finished: Kx=[20], N=231\n",
      "Time taken: 391.68 seconds\n",
      "Best criterion: 4.411799572289958\n",
      "\n",
      "\n",
      "Running for Kx = [20], N = 237...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 11s 1s/step - loss: 73257192.0000 - val_loss: 197.5911\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 4s 960ms/step - loss: 159.9988 - val_loss: 89.3722\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 74.5370 - val_loss: 42.3585\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 35.1187 - val_loss: 21.6671\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 19.0499 - val_loss: 13.8958\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 12.8191 - val_loss: 10.5739\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 10.0107 - val_loss: 8.7234\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 8.3530 - val_loss: 7.4770\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 7.2158 - val_loss: 6.5962\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 4s 973ms/step - loss: 6.4069 - val_loss: 5.9501\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 5.8191 - val_loss: 5.5120\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 5.4225 - val_loss: 5.2109\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 5.1476 - val_loss: 4.9968\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 4.9524 - val_loss: 4.8421\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.8081 - val_loss: 4.7273\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 4.7052 - val_loss: 4.6505\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 4s 957ms/step - loss: 4.6363 - val_loss: 4.6019\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.5898 - val_loss: 4.5619\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.5535 - val_loss: 4.5189\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.5088 - val_loss: 4.4855\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 4.4814 - val_loss: 4.4679\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.4621 - val_loss: 4.4391\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 4s 959ms/step - loss: 4.4346 - val_loss: 4.4240\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 4.4213 - val_loss: 4.4072\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 4.4025 - val_loss: 4.3848\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 4.3838 - val_loss: 4.3744\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 4.3737 - val_loss: 4.3676\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 4s 957ms/step - loss: 4.3651 - val_loss: 4.3527\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 4s 976ms/step - loss: 4.3503 - val_loss: 4.3389\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.3369 - val_loss: 4.3262\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.3222 - val_loss: 4.3075\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 4.3064 - val_loss: 4.3023\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 4s 963ms/step - loss: 4.3011 - val_loss: 4.2914\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.2905 - val_loss: 4.2802\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 4.2753 - val_loss: 4.2600\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 4.2576 - val_loss: 4.2518\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.2529 - val_loss: 4.2528\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 4.2505 - val_loss: 4.2317\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.2251 - val_loss: 4.2120\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.2124 - val_loss: 4.2144\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 4.2140 - val_loss: 4.2116\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 4.2108 - val_loss: 4.2056\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 4.2026 - val_loss: 4.1931\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 4.1905 - val_loss: 4.1865\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 4s 985ms/step - loss: 4.1853 - val_loss: 4.1791\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 4.1800 - val_loss: 4.1851\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 4.1870 - val_loss: 4.1853\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 4.1795 - val_loss: 4.1703\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 4.1665 - val_loss: 4.1728\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 4.1726 - val_loss: 4.1727\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.1623 - val_loss: 4.1550\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.1546 - val_loss: 4.1725\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 4.1661 - val_loss: 4.1531\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.1470 - val_loss: 4.1545\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.1578 - val_loss: 4.1395\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.1390 - val_loss: 4.1305\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.1408 - val_loss: 4.1334\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 4.1390 - val_loss: 4.1223\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.1308 - val_loss: 4.1234\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 4.1351 - val_loss: 4.1251\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.1381 - val_loss: 4.1214\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 4.1364 - val_loss: 4.1115\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.1207 - val_loss: 4.1096\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 4s 971ms/step - loss: 4.1392 - val_loss: 4.1340\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 4.1417 - val_loss: 4.0958\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.1167 - val_loss: 4.1110\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 4.1304 - val_loss: 4.1016\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 4.1275 - val_loss: 4.1082\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 4.1218 - val_loss: 4.0912\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 4.1145 - val_loss: 4.0959\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 4.1114 - val_loss: 4.0858\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 4.1171 - val_loss: 4.0921\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.0972 - val_loss: 4.0734\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 4.1027 - val_loss: 4.0705\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 4.0845 - val_loss: 4.0795\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 4.0997 - val_loss: 4.0608\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 4.0717 - val_loss: 4.0734\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 4s 957ms/step - loss: 4.0928 - val_loss: 4.0545\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 4.0744 - val_loss: 4.0660\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 4.0730 - val_loss: 4.0465\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 4.0662 - val_loss: 4.0488\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 4.0602 - val_loss: 4.0531\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 4s 965ms/step - loss: 4.0704 - val_loss: 4.0429\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 4.0503 - val_loss: 4.0456\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 4.0599 - val_loss: 4.0368\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.0564 - val_loss: 4.0499\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.0518 - val_loss: 4.0315\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 4s 963ms/step - loss: 4.0469 - val_loss: 4.0265\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 4.0401 - val_loss: 4.0455\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 4.0509 - val_loss: 4.0215\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 4.0326 - val_loss: 4.0252\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.0352 - val_loss: 4.0356\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 4s 956ms/step - loss: 4.0444 - val_loss: 4.0182\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 4s 950ms/step - loss: 4.0249 - val_loss: 4.0174\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 4.0228 - val_loss: 4.0186\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 4.0335 - val_loss: 4.0168\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 4.0159 - val_loss: 4.0118\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 4s 956ms/step - loss: 4.0208 - val_loss: 4.0031\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 4.0146 - val_loss: 4.0219\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 4.0204 - val_loss: 3.9993\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0710\n",
      "Function value obtained: 3.9839\n",
      "Current minimum: 3.9839\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0746\n",
      "Function value obtained: 4.0148\n",
      "Current minimum: 3.9839\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0620\n",
      "Function value obtained: 3.9760\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0559\n",
      "Function value obtained: 3.9847\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1325\n",
      "Function value obtained: 3.9887\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1742\n",
      "Function value obtained: 3.9947\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1769\n",
      "Function value obtained: 3.9760\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1439\n",
      "Function value obtained: 3.9763\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1445\n",
      "Function value obtained: 3.9839\n",
      "Current minimum: 3.9760\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1581\n",
      "Function value obtained: 3.9909\n",
      "Current minimum: 3.9760\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Finished: Kx=[20], N=237\n",
      "Time taken: 422.10 seconds\n",
      "Best criterion: 3.9759627457579327\n",
      "\n",
      "\n",
      "Running for Kx = [20], N = 250...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 11s 1s/step - loss: 73626208.0000 - val_loss: 54.5411\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 5s 1s/step - loss: 42.5691 - val_loss: 21.9401\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 18.1973 - val_loss: 11.2008\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.6856 - val_loss: 6.6117\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.0430 - val_loss: 5.0807\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 4s 992ms/step - loss: 4.9183 - val_loss: 4.5881\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 4s 998ms/step - loss: 4.5190 - val_loss: 4.3191\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 4.3126 - val_loss: 4.2212\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.2023 - val_loss: 4.1518\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.1424 - val_loss: 4.0853\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 4.0808 - val_loss: 4.0584\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 4s 993ms/step - loss: 4.0534 - val_loss: 4.0027\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.0039 - val_loss: 3.9940\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 4s 998ms/step - loss: 3.9864 - val_loss: 3.9592\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 4s 987ms/step - loss: 3.9637 - val_loss: 3.9375\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 4s 992ms/step - loss: 3.9272 - val_loss: 3.9095\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.9068 - val_loss: 3.8784\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 3.8742 - val_loss: 3.8525\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 3.8494 - val_loss: 3.8248\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.8220 - val_loss: 3.8070\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 4s 990ms/step - loss: 3.8088 - val_loss: 3.8002\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 4s 997ms/step - loss: 3.7887 - val_loss: 3.7650\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 4s 980ms/step - loss: 3.7628 - val_loss: 3.7627\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 4s 981ms/step - loss: 3.7565 - val_loss: 3.7447\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 3.7483 - val_loss: 3.7358\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.7279 - val_loss: 3.7071\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 4s 976ms/step - loss: 3.7110 - val_loss: 3.7043\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 4s 980ms/step - loss: 3.7045 - val_loss: 3.6905\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 4s 989ms/step - loss: 3.6975 - val_loss: 3.6881\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 3.6933 - val_loss: 3.7064\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 4s 990ms/step - loss: 3.6976 - val_loss: 3.6606\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 4s 981ms/step - loss: 3.6550 - val_loss: 3.6619\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 3.6631 - val_loss: 3.6594\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 4s 998ms/step - loss: 3.6489 - val_loss: 3.6452\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 4s 988ms/step - loss: 3.6450 - val_loss: 3.6564\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 4s 984ms/step - loss: 3.6428 - val_loss: 3.6296\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 4s 974ms/step - loss: 3.6233 - val_loss: 3.6297\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 4s 981ms/step - loss: 3.6346 - val_loss: 3.6559\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 4s 987ms/step - loss: 3.6288 - val_loss: 3.5978\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 4s 983ms/step - loss: 3.5977 - val_loss: 3.6061\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.6076 - val_loss: 3.5929\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 3.5899 - val_loss: 3.5868\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 3.5911 - val_loss: 3.6007\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 4s 980ms/step - loss: 3.5965 - val_loss: 3.5947\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 4s 987ms/step - loss: 3.5918 - val_loss: 3.5896\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 3.5818 - val_loss: 3.5783\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 4s 990ms/step - loss: 3.5753 - val_loss: 3.5787\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 4s 978ms/step - loss: 3.5763 - val_loss: 3.5793\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 4s 992ms/step - loss: 3.5745 - val_loss: 3.5722\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 4s 995ms/step - loss: 3.5690 - val_loss: 3.5710\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5675 - val_loss: 3.5643\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.5613 - val_loss: 3.5675\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 4s 982ms/step - loss: 3.5682 - val_loss: 3.5830\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 3.5748 - val_loss: 3.5717\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 4s 998ms/step - loss: 3.5665 - val_loss: 3.5786\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 4s 993ms/step - loss: 3.5764 - val_loss: 3.5815\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0849\n",
      "Function value obtained: 3.5643\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0809\n",
      "Function value obtained: 4.3718\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0627\n",
      "Function value obtained: 4.6577\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0618\n",
      "Function value obtained: 3.5643\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.2342\n",
      "Function value obtained: 4.3617\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2104\n",
      "Function value obtained: 4.0387\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1539\n",
      "Function value obtained: 4.0344\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1541\n",
      "Function value obtained: 3.5643\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1638\n",
      "Function value obtained: 3.6640\n",
      "Current minimum: 3.5643\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1607\n",
      "Function value obtained: 6.5381\n",
      "Current minimum: 3.5643\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Finished: Kx=[20], N=250\n",
      "Time taken: 254.81 seconds\n",
      "Best criterion: 3.5642943641664537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "order = 2\n",
    "batch_size = 2**8\n",
    "patience = 5\n",
    "latent_dim = 4\n",
    "\n",
    "# Define experiments\n",
    "experiments = [\n",
    "    {\"Kx\": [15], \"N_list\": [136, 142, 160]},\n",
    "    {\"Kx\": [20], \"N_list\": [231, 237, 250]},\n",
    "]\n",
    "\n",
    "# Run loop\n",
    "for exp in experiments:\n",
    "    Kx = exp[\"Kx\"]\n",
    "    for N in exp[\"N_list\"]:\n",
    "        print(f\"\\nRunning for Kx = {Kx}, N = {N}...\")\n",
    "        start_time = time()\n",
    "\n",
    "        model = ScalarOnScalarModel(Kx=Kx, order=order)\n",
    "        optimizer = NBDO(model=model, latent_dim=latent_dim)\n",
    "\n",
    "        optimizer.compute_train_set(num_designs=1_000, runs=N, type=\"random\")\n",
    "        history = optimizer.fit(epochs=epochs, patience=patience, batch_size=batch_size)\n",
    "        best_cr, best_des = optimizer.optimize()\n",
    "\n",
    "        end_time = time()\n",
    "        print(f\"Finished: Kx={Kx}, N={N}\")\n",
    "        print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Best criterion: {best_cr}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "design1.csv: A-optimality criterion = 5.60\n",
      "design2.csv: A-optimality criterion = 4.61\n",
      "design3.csv: A-optimality criterion = 3.10\n",
      "design4.csv: A-optimality criterion = 6.12\n",
      "design5.csv: A-optimality criterion = 5.34\n",
      "design6.csv: A-optimality criterion = 4.17\n",
      "design7.csv: A-optimality criterion = 4.59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "# Path to your data folder\n",
    "data_dir = './'\n",
    "\n",
    "# Function to build full second-order model matrix\n",
    "def build_model_matrix(df):\n",
    "    X = df.copy()\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Intercept\n",
    "    intercept = np.ones((n, 1))\n",
    "\n",
    "    # First-order terms\n",
    "    first_order = X.values\n",
    "\n",
    "    # Quadratic terms (squares)\n",
    "    quadratic = (X ** 2).values\n",
    "\n",
    "    # Interaction terms\n",
    "    interaction_terms = []\n",
    "    for i, j in combinations(X.columns, 2):\n",
    "        interaction_terms.append((X[i] * X[j]).values.reshape(-1, 1))\n",
    "    interaction = np.hstack(interaction_terms)\n",
    "\n",
    "    # Combine all components\n",
    "    M = np.hstack([intercept, first_order, quadratic, interaction])\n",
    "    return M\n",
    "\n",
    "# Function to compute A-optimality criterion\n",
    "def a_optimality_criterion(M):\n",
    "    XtX = M.T @ M\n",
    "    try:\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        return np.trace(XtX_inv)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.nan  # In case matrix is singular\n",
    "\n",
    "# Evaluate and print A-optimality for all six files\n",
    "for i in range(1, 8):\n",
    "    file_name = f'design{i}.csv'\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        M = build_model_matrix(df)\n",
    "        crit = a_optimality_criterion(M)\n",
    "        print(f\"{file_name}: A-optimality criterion = {crit:.2f}\")\n",
    "    else:\n",
    "        print(f\"{file_name}: File not found.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optidex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
